# LUNeXt 性能優化指南

本文檔提供關於如何優化 LUNeXt 訓練過程以解決訓練過程中速度下降問題的詳細指南。

## 問題診斷

我們發現在訓練多個 epoch 後，訓練速度明顯下降，即使 GPU 記憶體使用量看起來不高（僅 0.74GB/4GB）。這可能是由以下原因引起的：

1. GPU 溫度過高導致降頻
2. 記憶體碎片化
3. CUDA 上下文累積
4. DataLoader 工作進程資源洩漏
5. 計算圖未完全釋放

## 已實施的優化

我們已經對代碼進行了以下優化：

1. **記憶體管理優化**
   - 增加了顯式記憶體釋放（`torch.cuda.empty_cache()`）
   - 重置 CUDA 峰值記憶體統計
   - 添加了垃圾回收調用

2. **計算效率優化**
   - 使用分批處理來減少峰值記憶體使用
   - 優化 DataLoader 配置，避免工作進程資源累積
   - 顯式刪除不再需要的中間張量

3. **系統監控工具**
   - 添加了 GPU 溫度監控
   - 添加了降頻檢測
   - 提供系統記憶體使用情況報告

4. **自適應批次大小**
   - 根據可用 GPU 記憶體和模型類型自動調整批次大小
   - 異常處理 OOM (Out Of Memory) 錯誤，自動縮小批次大小重試

## 使用方法

### 1. 安裝必要依賴

首先，安裝新添加的依賴：

```bash
pip install -r requirements.txt
```

主要新增的依賴包括：
- `psutil`: 系統資源監控工具
- `pynvml`: NVIDIA GPU 監控工具

### 2. 使用性能優化檢查工具

我們提供了 `optimize_gpu.py` 工具來檢查和優化 GPU 設置：

```bash
python optimize_gpu.py check_only
```

這將檢查您的 GPU 狀態，包括溫度、風扇速度、是否處於降頻狀態等，而不啟動訓練。

### 3. 使用優化版本進行訓練

要使用所有優化功能進行訓練，只需執行：

```bash
python optimize_gpu.py
```

這將自動執行系統優化並啟動訓練流程。

### 4. 監控 GPU 溫度

如果 GPU 溫度過高，可能會導致自動降頻，這是導致訓練速度下降的常見原因。確保您的 GPU 散熱正常：

1. 清潔風扇和散熱片
2. 確保機箱通風良好
3. 考慮降低環境溫度
4. 外部 GPU 可以考慮使用額外的散熱風扇

### 5. 自定義配置

您可以在 `trainer/k_fold.py` 中的 `main` 函數中調整以下參數：

```python
MODEL_TYPE = "LUNeXt"  # 或 "UNet"
K_FOLD = 5             # 交叉驗證折數
TIMES = 3              # 重複次數
BATCH_SIZE = 16        # 批次大小
```

對於大型模型或較低規格的 GPU，建議減小批次大小。

## 性能診斷

如果優化後仍然遇到性能問題，請檢查以下方面：

1. **GPU 溫度**：如果溫度持續超過 80°C，幾乎肯定會導致降頻。
2. **系統負載**：確保沒有其他進程消耗大量 CPU 或 GPU 資源。
3. **驅動程序**：確保 NVIDIA 驅動程序是最新的。
4. **記憶體碎片化**：長時間訓練可能導致記憶體碎片化，定期重啟訓練腳本。

## 已知問題與解決方案

1. **問題**: 訓練過程中速度逐漸下降
   **解決方案**: 每完成一定數量的 epoch 後，保存檢查點並重啟訓練

2. **問題**: GPU 溫度過高
   **解決方案**: 加強散熱、減小批次大小、降低環境溫度

3. **問題**: 記憶體洩漏
   **解決方案**: 已添加顯式的記憶體釋放和垃圾回收，應該不再是問題

## 建議的硬體配置

- NVIDIA GPU 顯卡（建議 GeForce RTX 系列）
- 充足的系統記憶體（建議 16GB 以上）
- SSD 存儲以加速數據讀取
- 散熱良好的環境

---

如有任何問題或建議，請隨時反饋。祝訓練順利！
